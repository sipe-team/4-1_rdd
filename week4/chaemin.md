# 채팅 상담 데이터 파이프라인 전환 회고
### Kafka Connect 사용이 최선의 선택이었을까?

고객센터 상담 채팅 솔루션을 제공하는 파트너사는 기존에 RabbitMQ를 통해 채팅 데이터를 고객센터 DB에 연동하고 있었으나, 전사 기술 표준화 과제에 따라 Kafka 기반 구조로의 전환이 요구되었다. 이에 따라 파트너사는 단순히 RabbitMQ에서 Kafka로 Pub 코드만 변경하면 되는데에도 불구하고 터무니 없는 공수비용을 요구하였다. 따라서 비용 절감을 위해서 내부에서 직접 파이프라인 전환 개발을 수행하기로 결정하였다.

그렇다면 RabbitMQ를 대체할 솔루션이나 기술들은 많을텐데 왜 Kafka Connect를 선택했을까? 전환을 해야하는 여러 기능들이 존재했었는데, 다음과 같이 각각의 기능에 따라서 몇 가지의 고민을 했었던 것 같다.

우선적으로 가장 간단하게 전환을 할 수 있었던 순수 Kafka를 쓰지 않은 이유는 채팅 솔루션 소스코드를 우리가 직접 만질 수는 없었기 때문에 불가능했다. 하지만 채팅 솔루션 DB는 우리가 사용하지는 않지만 DB 자체는 우리가 관리하고 있었기 때문에 DB를 사용한 개발은 가능했었다.

이런 상황에서 나는 기능에 따라 다음과 같은 고민을 할 수 있었다.

- 채팅 상담 시작, 종료 데이터 적재 파이프라인
	- 상담사가 상담을 할당 받으면 '상담 시작' 상태가 되고, 상담사 또는 고객이 상담 종료를 누르거나 무응답으로 인하여 자동 종료가 되면 '상담 종료' 상태로 간주하여 이력을 쌓는 기능
	- 상담사의 실적을 판단할 수 있는 이력성 데이터로 데이터가 유실되면 안되고, **상담사가 후처리를 할 수 있도록 완전 실시간은 아니더라도 준실시간 정도는 되어야함**
	- 이력성으로 데이터를 쌓기 때문에 배치 시스템으로 데이터를 적재할 수 있었지만 준실시간은 되어야 상담사가 불편을 호소하지 않을 것이라고 판단하여 PostgreSQL + Kafka Connect를 사용하였다.
- 읽지 않은 채팅 메시지 알림
	- 고객이 채팅 상담을 하다가 다른 업무를 진행하느라 상담사가 남긴 채팅을 한 동안 읽지 않고 있을 때, 알림톡으로 알림을 보내는 기능
	- 단순 알림 기능으로 데이터가 유실되어도 큰 상관은 없지만, 알림이 한 번 나갈것이 두 번 이상 발송되면 고객의 클레임이 들어올 가능성이 있음
	- 채팅 상담중에 대부분의 고객은 채팅을 하다가 이탈할 가능성이 적고, 읽지 않은 채팅이 존재하는데 알림이 오지 않는다면 클레임이 오지는 않는다. 이렇게 알림의 중요성을 고려했을 때 주기가 짧은 배치 시스템이 적합하다고 판단하였다. PostgreSQL + Kafka Connect를 사용해도 무관하지만 배보다 배꼽이 더 큰 느낌이 강했다.
- 채팅 상담 자동종료예정 알림
	- 고객이 채팅 상담을 진행하다가 무응답 상태로 일정 시간동안 있는다면 자동으로 채팅 상담이 2분 뒤에 종료 예정이라고 고객에게 알림톡으로 알림을 보내는 기능
	- 단순 알림 기능이지만 데이터가 유실되면 고객이 종료알림을 받지 못해서 고객이 상담사의 친절 유무에 대해서 클레임이 들어올 수 있음.
	- 알림이 한 번 나갈것이 두 번 이상 발송되면 고객의 클레임이 들어올 가능성이 있음
	- 금방 종료되는 알림이므로 고객에게 최대한 빨리 알림을 보낼 필요가 있는 기능임
	- 알림의 중요성과 시급성을 고려했을 때 배치 시스템 보다는 PostgreSQL + Kafka Connect를 사용하였다.
- 판매자톡 접수 알림
	- 판매자와 고객이 진행하는 채팅 상담 기능으로, 고객이 판매자에게 채팅 상담을 요청하면 담당 판매자의 알림톡으로 알림을 전송하는 기능
	- 판매자가 **즉각적**으로 고객의 판매자톡 요청에 대해서 반응하지 못한다면 판매자에게 강성 클레임이 들어올 수 있으므로 데이터가 유실되면 큰 타격이 있을 수 있음
	- 알림의 중요성과 시급성을 고려했을 때 배치 시스템 보다는 PostgreSQL + Kafka Connect를 사용하였다.

### 재처리 로직을 구현해야 했을까?

위에서 말한 기능들은 PostgreSQL + Kafka Source Connector를 사용해서 Sink 부분은 고객센터 서버에서 Consume 하여 처리하고 있다. 이미 Consume을 한 데이터에 대해서 로직 상 에러가 발생한다면 DLQ 느낌으로 DB에 실패 케이스를 저장하고 관리자 페이지에서 재처리를 할 수 있도록 구현이 되어있다.

이렇게 실패 케이스에 대한 DLQ를 구현해놓았고, 재처리 케이스를 고려할 시간이 부족했기 때문에 재처리를 해야할까에 대한 고민을 하지 못하고 과제는 종료했었다. 모든 기능에 대해서 재처리 로직이 필요하지 않겠지만 데이터의 중요도에 따라서 재처리 로직을 추가하면 좋지 않을까?

예를들어 하필 에러가 발생하고 DLQ에 넣는 찰나에 네트워크 지연이 발생해서 DB에 INSERT를 못하고 쿼리 타임아웃이 발생한다면 데이터의 유실이 발생할 것이다. 하지만 재처리 로직을 추가하여 DLQ까지 떨어지기 전에 재처리 시도에 성공하여 DLQ까지 떨어지지 않았다면 데이터 유실이 발생하지 않았을 것이다. 또한 재처리 시도가 모두 실패했다 한들 네트워크가 그 시점에 정상화되어 DLQ에 저장되어 데이터는 유실되지 않을 수 있었을 것이다.

그 때는 갑작스럽게 1달도 안되는 시간에 이 기능들을 모두 전환하라고 해서 급하게 구현을 하느라 재처리 로직까지 고민할 시간이 없었던 것 같다. 요번 기회에 데이터의 중요도에 따라서 재처리 로직을 구현하여 데이터의 손실을 막을 수 있도록 해야겠다.